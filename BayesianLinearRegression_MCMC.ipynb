{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ベイズ線形回帰（MCMC）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "教師あり学習では{ (x_i,y_i) }のようなラベルの付いたデータからデータの隠された構造を推定するのが目的です。表題の回帰という語は出力変数yが連続的なときに用いられることが多いです。\n",
    "\n",
    "ここでは[ベイズ線形回帰（教師あり学習)](BayesianLinearRegression.ipynb)と同様の解析をマルコフ連鎖モンテカルロ法(MCMC)を用いて行います。\n",
    "\n",
    "変分ベイズがモデルをを近似した関数を　MCMCはサンプリングによって事後分布を推定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import edward as ed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変分ベイズの場合と同じ訓練データ、テストデータを用意します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_toy_dataset(N, w, noise_std=0.1):\n",
    "  D = len(w)\n",
    "  x = np.random.randn(N, D)\n",
    "  y = np.dot(x, w) + np.random.normal(0, noise_std, size=N)\n",
    "  return x, y\n",
    "\n",
    "N = 40  # number of data points\n",
    "D = 10  # number of features\n",
    "\n",
    "w_true = np.random.randn(D) #係数wの真の値\n",
    "X_train, y_train = build_toy_dataset(N, w_true)\n",
    "X_test, y_test = build_toy_dataset(N, w_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルも以前と同じでここではベイズ線形回帰モデル(Murphy, 2012[^1])を仮定します。入力$x_n \\in \\mathbb{R}^{D}$, 出力$y_n \\in \\mathbb{R}$間には線形の関係があるとします。\n",
    "\n",
    "N個のデータ点\n",
    "$(\\mathbf{X},\\mathbf{y})=\\{(\\mathbf{x}_n, y_n)\\}(X,y)={(x_n,y_n}) $に対しモデルは以下の分布関数で表される関係を仮定しています。\n",
    "\\begin{aligned} p(\\mathbf{w}) &= \\text{Normal}(\\mathbf{w} \\mid \\mathbf{0}, \\sigma_w^2\\mathbf{I}), \\\\[1.5ex] p(b) &= \\text{Normal}(b \\mid 0, \\sigma_b^2), \\\\ p(\\mathbf{y} \\mid \\mathbf{w}, b, \\mathbf{X}) &= \\prod_{n=1}^N \\text{Normal}(y_n \\mid \\mathbf{x}_n^\\top\\mathbf{w} + b, \\sigma_y^2).\\end{aligned}\n",
    "\n",
    "この線形モデルの隠れた変数は重み$\\mathbf{w}$と切片(バイアスとも言う)b です。$\\sigma_w^2,\\sigma_b^2$は事前分布の分散、$\\sigma_y^2$\n",
    "は尤度の分散です。尤度の平均は入力 $\\mathbf{x}_nx$ の線形変換として与えられています。\n",
    "\n",
    "Edwardでモデルを書きましょう。$\\sigma_w,\\sigma_b,\\sigma_y=1$\n",
    "と固定すると"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edward.models import Normal\n",
    "\n",
    "X = tf.placeholder(tf.float32, [N, D])\n",
    "w = Normal(loc=tf.zeros(D), scale=tf.ones(D))\n",
    "b = Normal(loc=tf.zeros([]), scale=tf.ones([]))\n",
    "y = Normal(loc=ed.dot(X, w) + b, scale=tf.ones(N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "と書けます。ここでXはtensorflowのplaceholderm[^2]です。推論処理の間、データに応じた値をこのpalceholderに渡すことになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推論ではEmpiricalクラスを用いて推定対象のモデルの変数を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edward.models import Empirical\n",
    "T = 5000  # number of samples\n",
    "qw = Empirical(params=tf.Variable(tf.random_normal([T, D])))\n",
    "qb = Empirical(params=tf.Variable(tf.random_normal([T])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは変分推論と時と同じ因子化された変数をqwとqbを使っています(これがベストなのかは判断が分かれます)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_HMC = ed.HMC({w: qw, b: qb}, data={X: X_train, y: y_train})\n",
    "inference_HMC.initialize(n_print=10, step_size=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wとqwの次元があっていないと以下のようなエラーが出てしまうので合わせたほうが良いです。\n",
    "\n",
    "https://discourse.edwardlib.org/t/bayesian-hacker-chapter1-introduction-imp-use-edward/299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [100%] ██████████████████████████████ Elapsed: 5s | Acceptance Rate: 1.000\n"
     ]
    }
   ],
   "source": [
    "inference_HMC.run(step_size=1e-3)\n",
    "qw_HMC,qb_HMC=qw,qb\n",
    "y_post_SGHMC = ed.copy(y, {w: qw, b: qb})\n",
    "#y_test=[int(i) for i in y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HMCの他にMetropolisHastings法やGibbsサンプリングも使うことが出来ます。所要時間とAcceptance rateを見るとHMCが相対的に収束が早いことがわかる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [100%] ██████████████████████████████ Elapsed: 5s | Acceptance Rate: 0.002\n"
     ]
    }
   ],
   "source": [
    "inference_MH = ed.MetropolisHastings({w: qw, b: qb},{w:w,b:b},data={X: X_train, y: y_train})\n",
    "#inference_MH.initialize(n_print=10, step_size=0.6)\n",
    "inference_MH.run()\n",
    "qw_MH,qb_MH=qw,qb\n",
    "y_post_MH = ed.copy(y, {w: qw, b: qb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [100%] ██████████████████████████████ Elapsed: 6s | Acceptance Rate: 1.000\n"
     ]
    }
   ],
   "source": [
    "inference_Gibbs = ed.Gibbs({w: qw, b: qb},{w:w,b:b}, data={X: X_train, y: y_train})\n",
    "#inference_Gibbs.initialize(n_print=10, step_size=0.6)\n",
    "inference_Gibbs.run()\n",
    "qw_Gibbs,qb_Gibbs=qw,qb\n",
    "y_post_Gibbs = ed.copy(y, {w: qw, b: qb})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criticism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMSE(X,X_test,y_post,y_test):\n",
    "    print(\"Mean squared error on test data:\")\n",
    "    print(ed.evaluate('mean_squared_error', data={X: X_test, y_post: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error on test data:\n",
      "12.4283\n"
     ]
    }
   ],
   "source": [
    "printMSE(X,X_test,y_post_SGHMC,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error on test data:\n",
      "12.2556\n"
     ]
    }
   ],
   "source": [
    "printMSE(X,X_test,y_post_MH,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error on test data:\n",
      "12.3137\n"
     ]
    }
   ],
   "source": [
    "printMSE(X,X_test,y_post_Gibbs,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
