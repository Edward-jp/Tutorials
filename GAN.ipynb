{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 敵対的生成ネットワーク(Generative Adversarial Network : GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "敵対的生成ネットワーク(GAN)は確率的モデリングの強力なアプローチです(I. Goodfellow et al., 2014; I. Goodfellow, 2016)。\n",
    "このモデルでは深層生成モデルを家庭し、速く正確な推論が可能になります。\n",
    "\n",
    "ここではEdwardでの例を示します。原文のWebページ版は　http://edwardlib.org/tutorials/gan　です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import edward as ed\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from edward.models import Uniform\n",
    "from observations import mnist\n",
    "from tensorflow.contrib import slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "  gs = gridspec.GridSpec(4, 4)\n",
    "  gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "  for i, sample in enumerate(samples):\n",
    "    ax = plt.subplot(gs[i])\n",
    "    plt.axis('off')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_aspect('equal')\n",
    "    plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed.set_seed(42)\n",
    "\n",
    "data_dir = \"/tmp/data\"\n",
    "out_dir = \"/tmp/out\"\n",
    "\n",
    "M = 128  # バッチサイズ\n",
    "d = 100  # 隠れ変数の次元"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "55,000 枚の$28\\times　28$画像で構成されたMNIST(LeCun, Bottou, Bengio, & Haffner, 1998)のデータを使います。\n",
    "それぞれの画像はflatにされた784次元ベクトルで表現されそれぞれの要素は0から1の間のピクセル値です。\n",
    "\n",
    "![GAN Fig 0](https://raw.githubusercontent.com/blei-lab/edward/master/docs/images/gan-fig0.png)\n",
    "\n",
    "このノートでのゴールは高い品質の手書き数字画像を生成するモデルを推定することです。\n",
    "\n",
    "訓練の間にMNISTの数字のバッチを取り込むことになります。tensorflowのplaceholderを固定したバッチサイズ$M$枚の画像に対してインスタンス化します。\n",
    "\n",
    "また例となるデータ全体の集合からから次のバッチのデータ点を選び出すヘルパー関数を定義します。\n",
    "これはある時点で処理中のバッチのインデックス(番号）を保持しておいて次のバッチを関数``next()``を使って返すものです。\n",
    "推測処理の間`x_train_generator`を使ってバッチを生成することになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(array, batch_size):\n",
    "  \"\"\"Generate batch with respect to array's first axis.\"\"\"\n",
    "  start = 0  # pointer to where we are in iteration\n",
    "  while True:\n",
    "    stop = start + batch_size\n",
    "    diff = stop - array.shape[0]\n",
    "    if diff <= 0:\n",
    "      batch = array[start:stop]\n",
    "      start += batch_size\n",
    "    else:\n",
    "      batch = np.concatenate((array[start:], array[:diff]))\n",
    "      start = diff\n",
    "    batch = batch.astype(np.float32) / 255.0  # normalize pixel intensities\n",
    "    batch = np.random.binomial(1, batch)  # binarize images\n",
    "    yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist(data_dir)\n",
    "x_train_generator = generator(x_train, M)\n",
    "x_ph = tf.placeholder(tf.float32, [M, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANは暗黙的な方法で生成モデルを仮定しています。与えられたランダムノイズに対しデータはその決定論的な関数として生成されるものとされます。\n",
    "\n",
    "形式的には生成の過程は$G(\\cdot; \\theta)$をサンプル$\\mathbf{\\epsilon}$を入力としてとるニューラルネットとして\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{\\epsilon} &\\sim p(\\mathbf{\\epsilon}), \\\\\n",
    "\\mathbf{x} &= G(\\mathbf{\\epsilon}; \\theta),\n",
    "\\end{align*}\n",
    "\n",
    "と書けます。分布$p(\\mathbf{\\epsilon})$は物理的システムに対して確率的な性質を入れるランダムノイズとして解釈されます。\n",
    "これは典型的には隠れた変数と同じ次元の一様分布または正規分布になります。\n",
    "\n",
    "EdwardではTensorFlow Slimを使ってニューラルネットを指定することで以下のようなモデルを作ります。\n",
    "これは２層全結合のニューラルネットと$[0,1]$間に値をとる$28\\times28$次元のベクトル出力として定義されます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generative_network(eps):\n",
    "  h1 = slim.fully_connected(eps, 128, activation_fn=tf.nn.relu)\n",
    "  x = slim.fully_connected(h1, 784, activation_fn=tf.sigmoid)\n",
    "  return x\n",
    "\n",
    "with tf.variable_scope(\"Gen\"):\n",
    "  eps = Uniform(tf.zeros([M, d]) - 1.0, tf.ones([M, d]))\n",
    "  x = generative_network(eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成的ネットワークを用いてデータの特徴を最もよく捉えるモデルのパラメーターを推定しようと思います。\n",
    "(GANを使う場合はパラメーターの推定が興味の対象で、隠れた変数の推定ではないことに注意)\n",
    "\n",
    "不幸なことに上で書いた確率モデルは取り扱いやすい尤度が認められません。\n",
    "これではモデルの密度を必要とするような多くの推測アルゴリズムは使えません。\n",
    "そこでここではモデルから得られるサンプルのみを仮定する尤度自由(\"likelihood-free\")アルゴリズム(Marin, Pudlo, Robert, & Ryder, 2012)\n",
    "を用いようと思います。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尤度自由アルゴリズムの発想の本質はモデルからのサンプルと真のデータの分布からのサンプルの間の不一致性(discrepancy)を解析することによる\n",
    "比較による学習です (e.g., Rubin (1984; Gretton, Borgwardt, Rasch, Schölkopf, & Smola, 2012))。\n",
    "モデルがより良いサンプルを生成するためにどこを改良すれば良いかの情報を持っています。\n",
    "    \n",
    "GANにおいてはニューラルネット$D(\\cdot;\\phi)$がこの比較を行い、識別器(discriminator)として知られています。\n",
    "$D(\\cdot;\\phi)$はデータ$\\mathbf{x}$を(モデルまたはデータの集合から取られたデータ点からの生成の)入力として取り、\n",
    "が真のデータから来る確率$\\mathbf{x}$を計算します。\n",
    "\n",
    "Edwardでは以下のような識別を使います。これはと1つのReLU隠れ層をもつフィードフォワードネットワークです。\n",
    "logit関数を適用した(拘束のない)スケールでの確率を返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminative_network(x):\n",
    "  \"\"\"Outputs probability in logits.\"\"\"\n",
    "  h1 = slim.fully_connected(x, 128, activation_fn=tf.nn.relu)\n",
    "  logit = slim.fully_connected(h1, 1, activation_fn=None)\n",
    "  return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p^*(\\mathbf{x})$を真のデータ分布を表現するものとするとGANを用いた最適化問題は\n",
    "\n",
    "\\begin{equation*}\n",
    "\\min_\\theta \\max_\\phi~\n",
    "\\mathbb{E}_{p^*(\\mathbf{x})} [ \\log D(\\mathbf{x}; \\phi) ]\n",
    "+ \\mathbb{E}_{p(\\mathbf{x}; \\theta)} [ \\log (1 - D(\\mathbf{x}; \\phi)) ].\n",
    "\\end{equation*}\n",
    "\n",
    "と書けます。この最適化問題は2つの手順からなっています。\n",
    "生成されたパラメータに従って最小の解を求める手順と識別パラメータに基づいて最大の解を求める手順です。\n",
    "\n",
    "実際にはアルゴリズムは勾配の更新を繰り返すことで進みます。\n",
    "追加の経験的な方法として生成モデルの目的関数を勾配の飽和を防ぐために変更するというのがあります(I. J. Goodfellow, 2014)。\n",
    "\n",
    "多くの直感的解釈の源がGAN的な訓練には存在します。\n",
    "その一つはこの方法の元々の動機の一つですが2つのニューラルネットがゲームをしているというアイデアに基づくものがあります。\n",
    "識別きは生成器から出されるサンプルを最もよく識別するようにし、生成器はなるべく識別器に識別されないようなサンプルを生成するようにするというものです。\n",
    "訓練のゴールはナッシュ均衡を実現することです。\n",
    "\n",
    "別のアイデアの源泉は教師あり学習としての教師なし学習です(M. U. Gutmann, Dutta, Kaski, & Corander, 2014; M. Gutmann & Hyvärinen, 2010)。\n",
    "これは識別問題—近年の問題は比較的に簡単な問題とされる—の力にレバレッジをかけるものです　。\n",
    "\n",
    "3つ目は古典的統計学の識別器は密度比の代理と解釈できるという点からきます\n",
    " (Mohamed & Lakshminarayanan, 2016; Sugiyama, Suzuki, & Kanamori, 2012)。\n",
    "元々の問題(最大尤度のような)識別器とモデルの密度を必要とするものを水増しすることで識別器が最適なものとなった場合は元の問題を再現できることになります。\n",
    "さらにこの近似はとても速く、近似推論としての見方からGANに正当性を与えています。\n",
    "\n",
    "EdwardではGANのアルゴリズム(`GANInference`)は単純に`x`とその実現`x_ph`であるを入力とした暗黙的な密度モデルを取ります。\n",
    "それに加えパラメトライズされた関数`discriminator`はサンプルを識別するために与えられます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference = ed.GANInference(\n",
    "    data={x: x_ph}, discriminator=discriminative_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここではADAMを生成器と識別器の両方の最適化に用います。\n",
    "15,000回のイテレーションを行い、1000回おきに進捗を表示します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "optimizer_d = tf.train.AdamOptimizer()\n",
    "\n",
    "inference = ed.GANInference(\n",
    "    data={x: x_ph}, discriminator=discriminative_network)\n",
    "inference.initialize(\n",
    "    optimizer=optimizer, optimizer_d=optimizer_d,\n",
    "    n_iter=15000, n_print=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下でGANを学習させるメインループを書きます。\n",
    "各イテレーションにおいてミニバッチが取り入れられパラメータがアルゴリズム(の結果）に基づいて更新されます。\n",
    "1000回のイテレーションごとに進捗を表示するとともにモデルから生成されたサンプルの画像を保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = ed.get_session()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "idx = np.random.randint(M, size=16)\n",
    "i = 0\n",
    "for t in range(inference.n_iter):\n",
    "  if t % inference.n_print == 0:\n",
    "    samples = sess.run(x)\n",
    "    samples = samples[idx, ]\n",
    "\n",
    "    fig = plot(samples)\n",
    "    plt.savefig(os.path.join(out_dir, '{}.png').format(\n",
    "        str(i).zfill(3)), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    i += 1\n",
    "\n",
    "  x_batch = next(x_train_generator)\n",
    "  info_dict = inference.update(feed_dict={x_ph: x_batch})\n",
    "  inference.print_progress(info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANの目的関数の収束を試験することは実際上は意味を持たないでしょう。\n",
    "このアルゴリズムは大抵サンプルの見た目が大丈夫であるかあるいはGANがデータの意味のある部分を再現することができた\n",
    "かなどある別の基準が満たされるまで走ることになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criticism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANの評価は未解決の問題(open problem)として残されています。\n",
    "データへの適合性の評価の観点からも、収束を達成しているかの点からも。\n",
    "\n",
    "最近の進展では別の目的関数とヒューリスティックが学習を安定化させるために考案されています。\n",
    "(Soumith Chintalaの　[GAN hacks repo](https://github.com/soumith/ganhacks)も参照).\n",
    "\n",
    "一つのモデル評価のアプローチは学習の間に生成された画像を単に目で見流というものがあります。\n",
    "以下に14,000回のイテレーション後に生成された画像を示します(これは14,000回生成器と識別器の勾配が更新されたものです)。\n",
    "\n",
    "![GAN Fig 1](https://raw.githubusercontent.com/blei-lab/edward/master/docs/images/gan-fig1.png)\n",
    "                                  \n",
    "この画像は少しぼやけていますが、有意義なものです。\n",
    "さらなる進展への提案として識別ネットワーク、生成ネットワークの容量を改善させるための\n",
    "最適化におけるハイパーパラメーターの調整、(畳み込み構造などの)さらなる事前情報を取り入れることなどがあります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
